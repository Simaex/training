{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Walkthrough - Forward Interest\n",
    "\n",
    "This walkthrough will take you through a simple classification task. By the end of the tutorial, you should be able to create a simple machine learning workflow to classify sentences for `forward interest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "\n",
    "To start, we'll quickly create a Squirro project that we can work in. To do this you'll need a running Squirro cluster and a valid API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmrILsd2QAmBji2aoYuvww\n"
     ]
    }
   ],
   "source": [
    "CLUSTER = \"https://unstable.squirro.net\"\n",
    "TOKEN = \"5de370f686a7bf4376eaab5080670c932fd9dd7bb3e2f79ef5d345571b992ad3f4b067aee6fd4f7990a08d009bb374135a7345b31f215892d95b08c515f6118f\"\n",
    "\n",
    "# get a client\n",
    "from squirro_client import SquirroClient\n",
    "client = SquirroClient(client_id=None, client_secret=None, cluster=CLUSTER)\n",
    "client.authenticate(refresh_token=TOKEN)\n",
    "\n",
    "# create a project\n",
    "PROJECT_ID = client.new_project(\"Classification Walkthrough\").get(\"id\")\n",
    "print PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The next step is to load data in our Squirro instance. We can now run a pre-made Squirro data loader script to insert our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-03 12:27:01,524 squirro_data_load[15621] INFO     Starting process (version {__VERSION_SHORT__}).\n",
      "2018-07-03 12:27:01,524 squirro_data_load[15621] WARNING  At least one of --source-steps, --source-profile, --source-config-file was specified, these are deprecated.\n",
      "2018-07-03 12:27:01,543 squirro_data_load[15621] INFO     Start load from csv\n",
      "2018-07-03 12:27:02,279 squirro.dataloader.sources.csv_src INFO     Auto-detected the encoding to be 'utf-8' with confidence of 0.99\n",
      "2018-07-03 12:27:02,279 squirro_data_load[15621] INFO     Loaded schema from data source. 3 columns are available:\n",
      "2018-07-03 12:27:02,279 squirro_data_load[15621] INFO       - dataset\n",
      "2018-07-03 12:27:02,280 squirro_data_load[15621] INFO       - label\n",
      "2018-07-03 12:27:02,280 squirro_data_load[15621] INFO       - text\n",
      "2018-07-03 12:27:03,688 squirro.dataloader.processor INFO     Processed 1000 rows. indexed:1000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:03,901 squirro.dataloader.processor INFO     Processed 2000 rows. indexed:2000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:04,123 squirro.dataloader.processor INFO     Processed 3000 rows. indexed:3000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:04,360 squirro.dataloader.processor INFO     Processed 4000 rows. indexed:4000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:04,572 squirro.dataloader.processor INFO     Processed 5000 rows. indexed:5000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:04,894 squirro.dataloader.processor INFO     Processed 6000 rows. indexed:6000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:05,120 squirro.dataloader.processor INFO     Processed 7000 rows. indexed:7000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:05,325 squirro.dataloader.processor INFO     Processed 8000 rows. indexed:8000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:05,548 squirro.dataloader.processor INFO     Processed 9000 rows. indexed:9000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:05,767 squirro.dataloader.processor INFO     Processed 10000 rows. indexed:10000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:05,978 squirro.dataloader.processor INFO     Processed 11000 rows. indexed:11000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:06,159 squirro.dataloader.processor INFO     Processed 12000 rows. indexed:12000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:06,383 squirro.dataloader.processor INFO     Processed 13000 rows. indexed:13000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:06,739 squirro.dataloader.processor INFO     Processed 14000 rows. indexed:14000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:07,044 squirro.dataloader.processor INFO     Processed 15000 rows. indexed:15000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:07,267 squirro.dataloader.processor INFO     Processed 16000 rows. indexed:16000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:07,557 squirro.dataloader.processor INFO     Processed 17000 rows. indexed:17000, deleted:0, skipped:0\n",
      "2018-07-03 12:27:07,802 squirro.dataloader.processor INFO     Processed 17935 rows. indexed:17935, deleted:0, skipped:0\n",
      "2018-07-03 12:27:07,807 squirro_data_load[15621] INFO     Total rows loaded to Squirro: 17935\n",
      "2018-07-03 12:27:07,811 squirro_data_load[15621] INFO     Total run time: 0:00:06.310455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "print subprocess.check_output([\"./load.sh\", CLUSTER, TOKEN, PROJECT_ID], stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the dataset\n",
    "\n",
    "The first step in any machine learning project should be to look carefully at your dataset. Try to answer questions like:\n",
    "- How many labeled samples do I have?\n",
    "- Are the labels evenly distributed between categories?\n",
    "- How accurate would I be if I labeled the samples randomly?\n",
    "- How accurate would I be if I labeled all the samples as only one category?\n",
    "Answering these questions will give you an idea of what method to use, what parameters to use for that method, and what the baseline perfomance might be.\n",
    "\n",
    "For the dataset we just loaded, we'll first look at a few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos - So, there are some clients that are looking to move that increased allocation to alternatives directly into the equity market for 2018 as they have become more bullish and that's in light of all of the things that you know about, whether it be tax rates, earnings, global growth, et cetera, et cetera that they may have\n",
      "neg - Unfortunately, like the industry we are impacted by higher cat losses in the quarter on the wildfires in California\n"
     ]
    }
   ],
   "source": [
    "# print a positive item\n",
    "for item in client.query(project_id=PROJECT_ID,\n",
    "                         query='dataset:train label:pos',\n",
    "                         fields=['body','keywords'], count=1)['items']:\n",
    "    print u'{label} - {body}'.format(body=item['body'], label=item['keywords']['label'][0])\n",
    "    \n",
    "# print a negative item\n",
    "for item in client.query(project_id=PROJECT_ID,\n",
    "                         query='dataset:train label:neg',\n",
    "                         fields=['body','keywords'], count=1)['items']:\n",
    "    print u'{label} - {body}'.format(body=item['body'], label=item['keywords']['label'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we've printed a single positive and negative example to get an idea of what we're looking for. No big surprises so far.\n",
    "\n",
    "Next we'll look at the dataset as a whole to get an idea of the balance between the two labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg - 4320\n",
      "pos - 1852\n"
     ]
    }
   ],
   "source": [
    "res = client.query(project_id=PROJECT_ID, query='*', aggregations={'label': {}})\n",
    "for value in res['aggregations']['label']['label']['values']:\n",
    "    print u'{label} - {count}'.format(label=value['key'], count=value['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, while our dataset has a decent number of samples (almost 18K), it has many more negative examples than positive. This imbalance should be noted, as it tells us a couple things. First, if we were to guess every item was negative, we'd already be ~85% correct! This is considerably higher than the random guessing baseline of 50%. Second, this imbalance might skew our model towards the negative category. To account for this, we should consider weighting the model categories when we construct our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model workflow\n",
    "\n",
    "Now that we have an idea of the data we're dealing with, we can move on to building our classification model. To reiterate the goal, we want to build a model that can guess a whether or not a sentence is forward-looking based on the text therein.\n",
    "\n",
    "The heart of Squirro's Machine Learning Service is our custom natural language processing library libNLP. It is what actually does all the processing. Thus our model workflow is simply a libNLP workflow, which we'll walk through now. (For extended documentation for libNLP, see https://squirro.github.io/nlp/).\n",
    "\n",
    "The libNLP workflow is simply a JSON file with specifications for individual components required for machine learning, so we start with an empty JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the dataset\n",
    "\n",
    "The first thing we need to do is tell libNLP on which dataset to operate. We do this by providing Squirro queries to `train`, `test`, and `infer` data sets. `train` is the data we want to train the model on. `test` is the data we'd like to test the model on, and `infer` is the data we'd like to predict on (which is typically unlabeled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[\"dataset\"] = {\n",
    "    \"train\": {\"query_string\": \"dataset:train\"},\n",
    "    \"test\": {\"query_string\": \"dataset:test\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have already split our dataset into a training and test set using a `dataset` facet during loading. Notice also that `query_string` can be any Squirro query, making it easy to carve out your samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the analyzer\n",
    "\n",
    "Next we want to tell libNLP the type of machine learning task we have. That way we can later analyze how well we are doing at this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[\"analyzer\"] = {\n",
    "    \"type\": \"classification\",\n",
    "    \"label_field\": \"keywords.label\",\n",
    "    \"tag_field\": \"keywords.label_pred\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we said we have a `classification` task, where the ground-truth label is `label` and the field with our predicted gender is `label_pred`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the pipeline\n",
    "\n",
    "Finally we need to tell libNLP the steps we'll use to go from unstructured text to a prediction for each item. We do so by defining a pipeline compose of sequential steps where each step does some operation on an internal stream of items.\n",
    "\n",
    "Here we only present the steps that we need for this task. For a list of all steps and associated documentation, see https://squirro.github.io/nlp/.\n",
    "\n",
    "First we instantiate an empty pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[\"pipeline\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loader step\n",
    "\n",
    "The first step is to load the data from Squirro into libNLP and convert them to libNLP's internal format. This step will be passed the various `dataset` settings we gave above since it is the beginning of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow['pipeline'].append({\n",
    "    \"step\": \"loader\",\n",
    "    \"type\": \"squirro_query\",\n",
    "    \"fields\": [\"body\", \"keywords.label\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we specified the `fields` we wanted to import to make loading more efficient.\n",
    "\n",
    "Also note, that when the loader step gets content, it will always turn it into a flat dictionary before passing it to the next step in the pipeline. This is why we prepend `keywords.` to the fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization step\n",
    "\n",
    "We next need to normalize the incoming data so that all the training samples are in the same format. This makes training the model simpler since it shrinks the space of data it has to be able to predict on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow['pipeline'].append({\n",
    "    \"step\": \"normalizer\",\n",
    "    \"types\": [\"html\", \"character\", \"punctuation\", \"lowercase\"],\n",
    "    \"fields\": [\"body\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for the field `body`, we are first stripping out `html`, numeric `character`s, and `punctuation`, and then making everything `lowercase`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization step\n",
    "\n",
    "Now we need to split our input from a stream of words into a list of tokens. For this particular case, we can use the `spaces` tokenizer to get our a sequential list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow['pipeline'].append({\n",
    "    \"step\": \"tokenizer\",\n",
    "    \"type\": \"spaces\",\n",
    "    \"fields\": [\"body\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding step\n",
    "\n",
    "Right before classification, we have to convert our list of tokenized words into numbers. This is done via an `embedder` step. Squirro comes shipped with some pre-trained embeddings, but for this case, we'll make our own TF-IDF embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow['pipeline'].append({\n",
    "    \"step\": \"embedder\",\n",
    "    \"type\": \"tfidf\",\n",
    "    \"input_field\": \"body\",\n",
    "    \"output_field\": \"embedded_body\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification step\n",
    "\n",
    "We are now ready to classify the incoming items. For this task we'll use a simple SVM classifier from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow['pipeline'].append({\n",
    "    \"step\": \"classifier\",\n",
    "    \"type\": \"sklearn\",\n",
    "    \"model_type\": \"SVC\",\n",
    "    \"model_kwargs\": {\"probability\": True},\n",
    "    \"use_sparse\": True,\n",
    "    \"input_fields\": [\"embedded_body\"],\n",
    "    \"label_field\": \"keywords.label\",\n",
    "    \"output_field\": \"keywords.label_pred\",\n",
    "    \"explanation_field\": \"keywords.label_pred_explanation\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier takes our input field `embedded_body` and attempts to predict the label field `keywords.label`. It writes its prediction in the output field `label_pred`.\n",
    "\n",
    "Some models also provide an explanation of their prediction (though the SVM does not). Here it's written to `keywords.label_pred_explanation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saver step\n",
    "\n",
    "Finally we want to save our predictions back to Squirro. We do this through a saver step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[\"pipeline\"].append({\n",
    "    \"step\": \"saver\",\n",
    "    \"type\": \"squirro_item\",\n",
    "    \"fields\": [\"keywords.label_pred\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only the fields we specify in `fields` will be sent back to Squirro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All together\n",
    "\n",
    "Putting it all together, our libNLP workflow looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipeline\": [\n",
      "    {\n",
      "      \"fields\": [\n",
      "        \"body\", \n",
      "        \"keywords.label\"\n",
      "      ], \n",
      "      \"step\": \"loader\", \n",
      "      \"type\": \"squirro_query\"\n",
      "    }, \n",
      "    {\n",
      "      \"fields\": [\n",
      "        \"body\"\n",
      "      ], \n",
      "      \"step\": \"normalizer\", \n",
      "      \"types\": [\n",
      "        \"html\", \n",
      "        \"character\", \n",
      "        \"punctuation\", \n",
      "        \"lowercase\"\n",
      "      ]\n",
      "    }, \n",
      "    {\n",
      "      \"fields\": [\n",
      "        \"body\"\n",
      "      ], \n",
      "      \"step\": \"tokenizer\", \n",
      "      \"type\": \"spaces\"\n",
      "    }, \n",
      "    {\n",
      "      \"step\": \"embedder\", \n",
      "      \"type\": \"tfidf\", \n",
      "      \"input_field\": \"body\", \n",
      "      \"output_field\": \"embedded_body\"\n",
      "    }, \n",
      "    {\n",
      "      \"step\": \"classifier\", \n",
      "      \"model_kwargs\": {\n",
      "        \"probability\": true\n",
      "      }, \n",
      "      \"input_fields\": [\n",
      "        \"embedded_body\"\n",
      "      ], \n",
      "      \"explanation_field\": \"keywords.label_pred_explanation\", \n",
      "      \"model_type\": \"SVC\", \n",
      "      \"label_field\": \"keywords.label\", \n",
      "      \"output_field\": \"keywords.label_pred\", \n",
      "      \"type\": \"sklearn\", \n",
      "      \"use_sparse\": true\n",
      "    }, \n",
      "    {\n",
      "      \"fields\": [\n",
      "        \"keywords.label_pred\"\n",
      "      ], \n",
      "      \"step\": \"saver\", \n",
      "      \"type\": \"squirro_item\"\n",
      "    }\n",
      "  ], \n",
      "  \"analyzer\": {\n",
      "    \"label_field\": \"keywords.label\", \n",
      "    \"tag_field\": \"keywords.label_pred\", \n",
      "    \"type\": \"classification\"\n",
      "  }, \n",
      "  \"dataset\": {\n",
      "    \"test\": {\n",
      "      \"query_string\": \"dataset:test\"\n",
      "    }, \n",
      "    \"train\": {\n",
      "      \"query_string\": \"dataset:train\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print json.dumps(workflow, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Now we're ready to train our proposed workflow. To do that we can simply push it to the Squirro Machine Learning Service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gphG4MTGO0QrEqZSOt4w\n"
     ]
    }
   ],
   "source": [
    "ml_workflow_id = client.new_machinelearning_workflow(\n",
    "    PROJECT_ID, name='gender_divide', config=workflow).get('id')\n",
    "print ml_workflow_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a training job for the workflow. This will tell the Machine Learning Service to schedule a job that runs the workflow with the `train` dataset we specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PtUzDitqSZ2BoQ-9xJOp1A\n"
     ]
    }
   ],
   "source": [
    "training_job_id = client.new_machinelearning_job(\n",
    "    PROJECT_ID, ml_workflow_id=ml_workflow_id, type='training').get('id')\n",
    "print training_job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just wait for it to finish. Depending on the size the dataset, size of the model, and the number of free parameters, this can take anywhere from a few seconds to days. Because of this, it's always a good idea to START SMALL with a test dataset and model until you're confident things are working well.\n",
    "\n",
    "Since training will take up to 5 minutes to finish, we write the simple function below that pings the job status every 5 seconds. Once this cell is done evaluating, we'll be ready to move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . . . . . . . . . . . PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:11,907 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:11,935 DEBUG    32%|###1      | 3001/9526 [00:02<00:05, 1097.62it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:12,035 DEBUG    37%|###7      | 3571/9526 [00:02<00:04, 1260.01it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:12,137 DEBUG    42%|####1     | 3968/9526 [00:02<00:04, 1351.21it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:12,558 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:12,629 DEBUG    45%|####5     | 4305/9526 [00:03<00:04, 1255.68it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:12,746 DEBUG    51%|#####1    | 4864/9526 [00:03<00:03, 1371.95it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:13,135 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:13,213 DEBUG    54%|#####4    | 5187/9526 [00:04<00:03, 1292.70it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:13,313 DEBUG    59%|#####9    | 5624/9526 [00:04<00:02, 1367.53it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:13,783 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:13,900 DEBUG    63%|######2   | 6001/9526 [00:04<00:02, 1276.98it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:14,008 DEBUG    69%|######8   | 6528/9526 [00:04<00:02, 1357.84it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:14,453 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:14,477 DEBUG    73%|#######3  | 7001/9526 [00:05<00:01, 1326.97it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:14,589 DEBUG    79%|#######9  | 7552/9526 [00:05<00:01, 1401.46it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:15,014 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:15,042 DEBUG    84%|########3 | 8001/9526 [00:05<00:01, 1369.73it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:15,153 DEBUG    90%|######### | 8576/9526 [00:05<00:00, 1440.73it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:15,646 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:15,673 DEBUG    94%|#########4| 9001/9526 [00:06<00:00, 1390.68it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:15,793 DEBUG    99%|#########9| 9472/9526 [00:06<00:00, 1436.87it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:15,908 DEBUG    9856it [00:06, 1469.42it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:27:16,179 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:16,224 DEBUG    10165it [00:07, 1447.34it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:27:16,319 DEBUG    10575it [00:07, 1485.68it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.utils.checkpoint 2018-07-03 14:27:16,336 INFO     checkpointed 10575 docs in 83 files\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,340 INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,914 INFO     adding document #10000 to Dictionary(8823 unique tokens: [u'issuances', u'four', u'hanging', u'looking', u'eligible']...)\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,952 INFO     built Dictionary(9067 unique tokens: [u'issuances', u'four', u'hanging', u'looking', u'eligible']...) from 10575 documents (total 252241 corpus positions)\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,958 INFO     discarding 0 tokens: []...\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,958 INFO     keeping 9067 tokens which were in no less than 1 and no more than 10575 (=100.0%) documents\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,961 DEBUG    rebuilding dictionary, shrinking gaps\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,967 INFO     resulting dictionary: Dictionary(9067 unique tokens: [u'issuances', u'four', u'hanging', u'looking', u'eligible']...)\n",
      "PV:- nlp_runner.0 gensim.corpora.dictionary 2018-07-03 14:27:16,967 DEBUG    rebuilding dictionary, shrinking gaps\n",
      "PV:- nlp_runner.0 gensim.models.tfidfmodel 2018-07-03 14:27:16,972 INFO     collecting document frequencies\n",
      "PV:- nlp_runner.0 gensim.models.tfidfmodel 2018-07-03 14:27:16,976 INFO     PROGRESS: processing document #0\n",
      "PV:- nlp_runner.0 gensim.models.tfidfmodel 2018-07-03 14:27:17,583 INFO     PROGRESS: processing document #10000\n",
      "PV:- nlp_runner.0 gensim.models.tfidfmodel 2018-07-03 14:27:17,617 INFO     calculating IDF weights for 10575 documents and 9066 features (217813 matrix non-zeros)\n",
      "PV:- nlp_runner.0 gensim.utils 2018-07-03 14:27:17,636 INFO     saving Dictionary object under /var/lib/squirro/machinelearning/n_gphG4MTGO0QrEqZSOt4w/tfidf, separately None\n",
      "PV:- nlp_runner.0 gensim.utils 2018-07-03 14:27:17,640 INFO     saved /var/lib/squirro/machinelearning/n_gphG4MTGO0QrEqZSOt4w/tfidf\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:27:17,823 INFO     training Step(step: classifier, type: sklearn)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.utils.checkpoint 2018-07-03 14:27:21,235 INFO     checkpointed 10575 docs in 83 files\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.classifiers.sklearn_classifier 2018-07-03 14:27:21,236 INFO     creating label maps\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.classifiers.sklearn_classifier 2018-07-03 14:27:22,207 INFO     input map size: 9067\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.classifiers.sklearn_classifier 2018-07-03 14:27:22,207 INFO     input map: {u'embedded_body': 0}\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.classifiers.sklearn_classifier 2018-07-03 14:27:23,242 INFO     label map size: 2\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.classifiers.sklearn_classifier 2018-07-03 14:27:23,243 INFO     label map: {u'neg': 0, u'pos': 1}\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.classifiers.sklearn_classifier 2018-07-03 14:27:23,243 INFO     vectorizing data\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.classifiers.sklearn_classifier 2018-07-03 14:27:31,866 INFO     training model\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,588 INFO     saving pipeline\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,588 INFO     saving Step(step: loader, type: squirro_query)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,588 INFO     saving Step(step: normalizer, type: html)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,589 INFO     saving Step(step: normalizer, type: character)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,589 INFO     saving Step(step: normalizer, type: punctuation)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,589 INFO     saving Step(step: normalizer, type: lowercase)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,589 INFO     saving Step(step: tokenizer, type: spaces)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,589 INFO     saving Step(step: embedder, type: tfidf)\n",
      "PV:- nlp_runner.0 gensim.utils 2018-07-03 14:28:10,589 INFO     saving Dictionary object under /var/lib/squirro/machinelearning/n_gphG4MTGO0QrEqZSOt4w/tfidf, separately None\n",
      "PV:- nlp_runner.0 gensim.utils 2018-07-03 14:28:10,594 INFO     saved /var/lib/squirro/machinelearning/n_gphG4MTGO0QrEqZSOt4w/tfidf\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:10,779 INFO     saving Step(step: classifier, type: sklearn)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,839 INFO     processing pipeline\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,839 INFO     processing Step(step: loader, type: squirro_query)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,839 INFO     processing Step(step: normalizer, type: html)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,839 INFO     processing Step(step: normalizer, type: character)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,839 INFO     processing Step(step: normalizer, type: punctuation)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,840 INFO     processing Step(step: normalizer, type: lowercase)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,840 INFO     processing Step(step: tokenizer, type: spaces)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,840 INFO     processing Step(step: embedder, type: tfidf)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:24,840 INFO     processing Step(step: classifier, type: sklearn)\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:28:24,887 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:24,888 INFO     loading 1769 items from Squirro\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:24,889 DEBUG    0%|          | 0/1769 [00:00<?, ?it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:28:25,421 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:25,458 DEBUG    0%|          | 1/1769 [00:00<16:45,  1.76it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:25,738 DEBUG    7%|7         | 128/1769 [00:00<00:10, 150.83it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:26,024 DEBUG    14%|#4        | 256/1769 [00:01<00:06, 225.61it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:26,211 DEBUG    22%|##1       | 384/1769 [00:01<00:04, 290.49it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:26,396 DEBUG    29%|##8       | 512/1769 [00:01<00:03, 339.69it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:26,586 DEBUG    36%|###6      | 640/1769 [00:01<00:02, 377.17it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:26,778 DEBUG    43%|####3     | 768/1769 [00:01<00:02, 406.49it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:26,969 DEBUG    51%|#####     | 896/1769 [00:02<00:02, 430.68it/s]\n",
      "PV:- nlp_runner.0 urllib3.connectionpool 2018-07-03 14:28:27,515 DEBUG    http://localhost:80 \"POST /api/topic/v0/squirro/projects/wmrILsd2QAmBji2aoYuvww/items/query HTTP/1.1\" 200 None\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:27,537 DEBUG    57%|#####6    | 1001/1769 [00:02<00:02, 378.08it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:27,729 DEBUG    59%|#####9    | 1049/1769 [00:02<00:01, 369.30it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:27,917 DEBUG    65%|######5   | 1152/1769 [00:03<00:01, 380.39it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:28,167 DEBUG    72%|#######2  | 1280/1769 [00:03<00:01, 390.43it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:28,353 DEBUG    80%|#######9  | 1408/1769 [00:03<00:00, 406.46it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:28,540 DEBUG    87%|########6 | 1536/1769 [00:03<00:00, 420.69it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:28,752 DEBUG    94%|#########4| 1664/1769 [00:03<00:00, 430.69it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.steps.loaders.squirro_query_loader 2018-07-03 14:28:28,758 DEBUG    100%|##########| 1769/1769 [00:03<00:00, 457.21it/s]\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,932 INFO     cleaning pipeline\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,932 INFO     cleaning Step(step: loader, type: squirro_query)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,932 INFO     cleaning Step(step: normalizer, type: html)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,932 INFO     cleaning Step(step: normalizer, type: character)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,932 INFO     cleaning Step(step: normalizer, type: punctuation)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,933 INFO     cleaning Step(step: normalizer, type: lowercase)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,933 INFO     cleaning Step(step: tokenizer, type: spaces)\n",
      "PV:- nlp_runner.0 squirro.lib.nlp.pipeline 2018-07-03 14:28:28,933 INFO     cleaning Step(step: embedder, type: tfidf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def wait_for_ml_job(project_id, ml_workflow_id, ml_job_id, max_wait_time=600):\n",
    "    \"\"\"Wait for ML job to finish\"\"\"\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        job = client.get_machinelearning_job(\n",
    "            project_id, ml_workflow_id, ml_job_id, include_run_log=True).get('machinelearning_job')\n",
    "        if job.get('last_error_at') is not None or job.get('last_success_at') is not None:\n",
    "            print job.get('logs')\n",
    "            break\n",
    "        else:\n",
    "            print '.',\n",
    "            time.sleep(5)\n",
    "        if (time.time() - start_time) > max_wait_time:\n",
    "            print 'max_wait_time has been exceeded!'\n",
    "            print job.get('logs')\n",
    "            break\n",
    "wait_for_ml_job(PROJECT_ID, ml_workflow_id, training_job_id, max_wait_time=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the model quality\n",
    "\n",
    "Now that our model is trained, we can check out how it performed on our test data set (again in this instance it was the same as the training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tag_counts\": {\n",
      "    \"neg\": {\n",
      "      \"neg\": 1390.1625575991, \n",
      "      \"pos\": 178.8374424009\n",
      "    }, \n",
      "    \"pos\": {\n",
      "      \"neg\": 60.9918041121, \n",
      "      \"pos\": 139.0081958879\n",
      "    }\n",
      "  }, \n",
      "  \"recall\": {\n",
      "    \"neg\": 0.8860182011, \n",
      "    \"pos\": 0.6950409794\n",
      "  }, \n",
      "  \"i_label_indexes\": {\n",
      "    \"1\": \"pos\", \n",
      "    \"0\": \"neg\"\n",
      "  }, \n",
      "  \"label_counts\": {\n",
      "    \"neg\": 1569, \n",
      "    \"pos\": 200\n",
      "  }, \n",
      "  \"precision\": {\n",
      "    \"neg\": 0.9579701473, \n",
      "    \"pos\": 0.4373449849\n",
      "  }, \n",
      "  \"confusion_matrix\": [\n",
      "    [\n",
      "      1390.1625575991, \n",
      "      178.8374424009\n",
      "    ], \n",
      "    [\n",
      "      60.9918041121, \n",
      "      139.0081958879\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = client.get_machinelearning_job(\n",
    "    PROJECT_ID, ml_workflow_id, training_job_id).get('machinelearning_job').get('last_result')\n",
    "print json.dumps(result, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results tell us several things. First, we see the `precision` and `recall` of each predicted label. `precision` is the number of true positives divided by the total number of predictions for each category. `recall` is the number of true positives divided by the total number of samples for each category.\n",
    "\n",
    "We also see the `confusion matrix` which shows us where we are most likely to mis-predict. In a perfect classifier, only the diagonal of the matrix would be populated. Here we see, though, that there is population is off-diagonal elements as well, meaning we are mis-predicting in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model has reasonble (though not perfect) quality, we can now move on to validating it on samples that don't yet have a `label`. We can do this in a few different ways, which we cover below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct inference\n",
    "\n",
    "First, it's good to do a sanity check. The simplest way to check our model on new data is to run a direct inference on items we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'neg': 0.4514311399}, {u'pos': 0.5485688601}] - We have the full support of the board moving forward.\n",
      "[{u'neg': 0.204776738}, {u'pos': 0.795223262}] - We will make sure we have enough runway for the next 12 months.\n",
      "[{u'neg': 0.9934103479}, {u'pos': 0.0065896521}] - Luke, I am your father.\n"
     ]
    }
   ],
   "source": [
    "test_items = [{\"id\": 0, \"body\": \"We have the full support of the board moving forward.\"},\n",
    "              {\"id\": 1, \"body\": \"We will make sure we have enough runway for the next 12 months.\"},\n",
    "              {\"id\": 2, \"body\": \"Luke, I am your father.\"}]\n",
    "\n",
    "test_items_pred = client.run_machinelearning_workflow(\n",
    "    PROJECT_ID, ml_workflow_id, data={'items': test_items}).get('items')\n",
    "for item, item_pred in zip(test_items, test_items_pred):\n",
    "    print u'{label} - {body}'.format(body=item['body'], label=item_pred['keywords']['label_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems reasonable..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a pipelet to for ingestion\n",
    "\n",
    "Now that we have some confidence in our trained model, we can set up a pipelet step that will run items through it during ingestion. For this we have made an example pipelet here: https://github.com/squirro/delivery/tree/master/templates/pipelets/machinelearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an inference job for future data\n",
    "\n",
    "If we want to avoid blocking the ingestion process, we can instead make an ayschronous inference job that will tag new items with our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffIquFvHT52O10MIjbGhiw\n"
     ]
    }
   ],
   "source": [
    "inference_job_id = client.new_machinelearning_job(\n",
    "    PROJECT_ID, ml_workflow_id=ml_workflow_id, type='inference', scheduling_options={}).get('id')\n",
    "print inference_job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset\n",
    "\n",
    "WARNING: This deletes the project!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_project(PROJECT_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
