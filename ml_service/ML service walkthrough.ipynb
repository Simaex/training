{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squirro machine learning service walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER='https://unstable.squirro.net'\n",
    "TOKEN='5de370f686a7bf4376eaab5080670c932fd9dd7bb3e2f79ef5d345571b992ad3f4b067aee6fd4f7990a08d009bb374135a7345b31f215892d95b08c515f6118f'\n",
    "PROJECT_ID='gqunGq56Qw6bIX36GLy6hg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Squirro client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squirro_client import SquirroClient\n",
    "client = SquirroClient(client_id=None, client_secret=None, cluster=CLUSTER)\n",
    "client.authenticate(refresh_token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create machine learning workflow\n",
    "\n",
    "The workflow defines:\n",
    "    - what data you'd like to train and infer on\n",
    "    - the keywords you'll use as features and labels\n",
    "    - what normalization/filtering/tokenization steps are required to manipulate the text\n",
    "    - what models you want to use and their associated hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_workflow = {\n",
    "  \"dataset\": {\n",
    "    \"train\": {\"query_string\": \"dataset:train (label:sci.space OR label:soc.religion.christian OR label:alt.atheism)\"},\n",
    "    \"process\": {\"query_string\": \"dataset:test (label:sci.space OR label:soc.religion.christian OR label:alt.atheism)\"}\n",
    "  },\n",
    "  \"analyzer\": {\n",
    "    \"type\": \"classification\",\n",
    "    \"tag_field\": \"keywords.pred_label\",\n",
    "    \"label_field\": \"keywords.label\"\n",
    "  },\n",
    "  \"pipeline\": [{\n",
    "    \"step\": \"loader\",\n",
    "    \"type\": \"squirro_query\",\n",
    "    \"fields\": [\"body\", \"title\", \"keywords.label\"]\n",
    "  },{\n",
    "    \"step\": \"filter\",\n",
    "    \"type\": \"empty\",\n",
    "    \"fields\": [\"body\", \"title\", \"keywords.label\"]\n",
    "  },{\n",
    "    \"step\": \"filter\",\n",
    "    \"type\": \"join\",\n",
    "    \"input_field\": \"keywords.label\",\n",
    "    \"output_field\": \"keywords.label\"\n",
    "  },{\n",
    "    \"step\": \"filter\",\n",
    "    \"type\": \"merge\",\n",
    "    \"input_fields\": [\"body\", \"title\"],\n",
    "    \"output_field\": \"text\"\n",
    "  },{\n",
    "    \"step\": \"normalizers\",\n",
    "    \"types\": [\"html\", \"punctuation\", \"lowercase\", \"character\"],\n",
    "    \"fields\": [\"text\"]\n",
    "  },{\n",
    "    \"step\": \"tokenizer\",\n",
    "    \"type\": \"spaces\",\n",
    "    \"fields\": [\"text\"]\n",
    "  },{\n",
    "    \"step\": \"embedder\",\n",
    "    \"type\": \"dictionary\",\n",
    "    \"batch_size\": 1024,\n",
    "    \"input_field\": \"text\",\n",
    "    \"output_field\": \"indexed_text\"\n",
    "  },{\n",
    "    \"step\": \"checkpoint\",\n",
    "    \"type\": \"disk\",\n",
    "    \"do_randomize\": True,\n",
    "    \"batch_size\": 1\n",
    "  },{\n",
    "    \"step\": \"classifier\",\n",
    "    \"type\": \"cnn_seq2one\",\n",
    "    \"batch_size\": 1024,\n",
    "    \"dict_name\": \"dictionary\",\n",
    "    \"dropout_fraction\": 0.5,\n",
    "    \"embedding_dim\": 50,\n",
    "    \"explanation_field\": \"explanantion\",\n",
    "    \"input_field\": \"indexed_text\",\n",
    "    \"label_field\": \"keywords.label\",\n",
    "    \"labels\": [\"soc.religion.christian\", \"alt.atheism\", \"sci.space\"],\n",
    "    \"max_sequence_length\": 1000,\n",
    "    \"mini_batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"output_field\": \"keywords.pred_label\"\n",
    "  },{\n",
    "    \"step\": \"saver\",\n",
    "    \"type\": \"squirro_item\",\n",
    "    \"batch_size\": 1000,\n",
    "    \"fields\": [\"keywords.pred_label\"]\n",
    "  }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload workflow\n",
    "\n",
    "This hands the workflow configuration (and any local pre-trained models) to the Squirro ML service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print len(client.get_machinelearning_workflows(PROJECT_ID).get('machinelearning_workflows'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_workflow_id = client.new_machinelearning_workflow(\n",
    "    PROJECT_ID, name='e2e_cnn', config=ml_workflow).get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training job\n",
    "\n",
    "We now tell Squirro that we want a training job for the ML workflow we just uploaded. This will train the models we defined. If nothing is in the queue, it should start immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print len(client.get_machinelearning_jobs(\n",
    "    PROJECT_ID, ml_workflow_id=ml_workflow_id).get('machinelearning_jobs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_id = client.new_machinelearning_job(\n",
    "    PROJECT_ID, ml_workflow_id=ml_workflow_id, type='training').get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def wait_for_ml_job(project_id, ml_workflow_id, ml_job_id):\n",
    "    \"\"\"Wait for ML job to finish\"\"\"\n",
    "    while True:\n",
    "        job = client.get_machinelearning_job(\n",
    "            project_id, ml_workflow_id, ml_job_id).get('machinelearning_job')\n",
    "        if job.get('last_error_at') is not None or job.get('last_success_at') is not None:\n",
    "            print job\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'total_runs': 1, u'next_run_time_at': u'2018-05-25T02:21:55', u'healthy': True, u'last_error': None, u'created_at': u'2018-05-24T08:08:57', u'modified_at': u'2018-05-24T08:18:01', u'last_error_at': None, u'ml_workflow_id': u'esr-srLARBmN47dAweaifg', u'last_success_at': u'2018-05-24T08:18:01', u'type': u'training', u'id': u'ks9GZEZCTuqcvIjiBE7Nxw', u'error_count': 0}\n",
      "{u'total_runs': 1, u'next_run_time_at': u'2018-05-25T02:21:55', u'healthy': True, u'last_error': None, u'created_at': u'2018-05-24T08:08:57', u'modified_at': u'2018-05-24T08:18:01', u'last_error_at': None, u'ml_workflow_id': u'esr-srLARBmN47dAweaifg', u'last_success_at': u'2018-05-24T08:18:01', u'type': u'training', u'id': u'ks9GZEZCTuqcvIjiBE7Nxw', u'error_count': 0}\n"
     ]
    }
   ],
   "source": [
    "print wait_for_ml_job(PROJECT_ID, ml_workflow_id, training_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on unlabeled data\n",
    "\n",
    "Just to make sure the model training is succesful, we try a synchronous inference on a few test items. This `run_machinelearning_workflow` is the same command used in the ML service pipelet: https://github.com/squirro/delivery/tree/master/templates/pipelets/machinelearning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "items = client.query(\n",
    "    PROJECT_ID,\n",
    "    query=\"dataset:test (label:sci.space OR label:soc.religion.christian OR label:alt.atheism)\",\n",
    "    fields=[\"body\", \"title\", \"keywords\"],\n",
    "    count=3\n",
    ").get('items')\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'soc.religion.christian'] [{u'soc.religion.christian': 0.9988566637}, {u'sci.space': 0.0}, {u'alt.atheism': 0.0011433086}]\n",
      "[u'soc.religion.christian'] [{u'soc.religion.christian': 1.0}, {u'sci.space': 0.0}, {u'alt.atheism': 2.14e-08}]\n",
      "[u'soc.religion.christian'] [{u'soc.religion.christian': 0.0249485839}, {u'sci.space': 0.000496073}, {u'alt.atheism': 0.9745553732}]\n"
     ]
    }
   ],
   "source": [
    "items = client.run_machinelearning_workflow(\n",
    "    PROJECT_ID, ml_workflow_id=ml_workflow_id, data={'items': items}).get('items')\n",
    "for item in items:\n",
    "    print item.get('keywords').get('label'), item.get('keywords').get('pred_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create inference job\n",
    "\n",
    "For regularly changing datasets, it is advantageous to set up scheduled inference jobs. These will run asynchronously to free up ingestion. Again, if nothing is in the queue, these should run immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print len(client.get_machinelearning_jobs(PROJECT_ID, ml_workflow_id=ml_workflow_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_job_id = client.new_machinelearning_job(\n",
    "    PROJECT_ID, ml_workflow_id=ml_workflow_id, type='inference').get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'total_runs': 1, u'next_run_time_at': u'2018-05-25T12:26:49', u'healthy': True, u'last_error': None, u'created_at': u'2018-05-24T08:18:06', u'modified_at': u'2018-05-24T08:18:12', u'last_error_at': None, u'ml_workflow_id': u'esr-srLARBmN47dAweaifg', u'last_success_at': u'2018-05-24T08:18:12', u'type': u'inference', u'id': u'vTO5K0ecQNyUU4fWCrhhdQ', u'error_count': 0}\n",
      "{u'total_runs': 1, u'next_run_time_at': u'2018-05-25T12:26:49', u'healthy': True, u'last_error': None, u'created_at': u'2018-05-24T08:18:06', u'modified_at': u'2018-05-24T08:18:12', u'last_error_at': None, u'ml_workflow_id': u'esr-srLARBmN47dAweaifg', u'last_success_at': u'2018-05-24T08:18:12', u'type': u'inference', u'id': u'vTO5K0ecQNyUU4fWCrhhdQ', u'error_count': 0}\n"
     ]
    }
   ],
   "source": [
    "print wait_for_ml_job(PROJECT_ID, ml_workflow_id, inference_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze training\n",
    "\n",
    "When training any model, it is important to iteratively check how well your models are doing. In the future, this functionality will be largely in the GUI. For now, however, we can check via libNLP (see libNLP walkthrough)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ml_workflow in client.get_machinelearning_workflows(PROJECT_ID).get('machinelearning_workflows'):\n",
    "    client.delete_machinelearning_workflow(PROJECT_ID, ml_workflow_id=ml_workflow.get('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchyas\n",
    "\n",
    "- multi-node training jobs not currently working\n",
    "- underfitting\n",
    "- overfitting\n",
    "- hyperparameter tuning\n",
    "- make sure documents make it through the pipeline\n",
    "- know your baselines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
