{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Walkthrough - Lead recommendation\n",
    "\n",
    "This walkthrough will take you through a simple recommendation task. By the end of the tutorial, you should be able to create a simple machine learning workflow to recommendation leads based on associated entity properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "\n",
    "To start, we'll quickly create a Squirro project that we can work in. To do this you'll need a running Squirro cluster and a valid API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER = \"https://unstable.squirro.net\"\n",
    "TOKEN = \"5de370f686a7bf4376eaab5080670c932fd9dd7bb3e2f79ef5d345571b992ad3f4b067aee6fd4f7990a08d009bb374135a7345b31f215892d95b08c515f6118f\"\n",
    "\n",
    "# get a client\n",
    "from squirro_client import SquirroClient\n",
    "client = SquirroClient(client_id=None, client_secret=None, cluster=CLUSTER)\n",
    "client.authenticate(refresh_token=TOKEN)\n",
    "\n",
    "# create a project\n",
    "PROJECT_ID = client.new_project(\"Recommendation Walkthrough\").get(\"id\")\n",
    "print PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pretrained models\n",
    "\n",
    "Before we load any data, we'll upload 3 pretrained models to find `forward-looking interest` statements, and tag them with a `deal type` and `industry`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load forward interest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./forward_interest/fasttext_quantized.json', 'rb') as f:\n",
    "    forward_interest_workflow = json.load(f)\n",
    "forward_interest_workflow_id = client.new_machinelearning_workflow(\n",
    "    PROJECT_ID, name='forward_interest', config=forward_interest_workflow,\n",
    "    ml_models='./forward_interest').get('id')\n",
    "print forward_interest_workflow_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load deal type model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./deal_type/tfidf_sgd/tfidf_sgd.json', 'rb') as f:\n",
    "    deal_type_workflow = json.load(f)\n",
    "deal_type_workflow_id = client.new_machinelearning_workflow(\n",
    "    PROJECT_ID, name='deal_type', config=deal_type_workflow,\n",
    "    ml_models='./deal_type/tfidf_sgd').get('id')\n",
    "print deal_type_workflow_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a tagging pipelet\n",
    "\n",
    "Now that our ML models are on the server, we can use the Machine Learning Service to create entities and tag items on ingestion. For this task, we'll use a premade pipelet that first classifies each sentence as forward-looking or not. If a sentence is forward-looking, then we attempt to tag it with a deal type and industry. All 3 models will be applied with a threshold confidence that must be met to apply the tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing pipelet configuration\n",
    "\n",
    "Before using the pipelet, we have to change its configuration to point to our newly created models and project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pipelet_config.json', 'rb') as f:\n",
    "    pipelet_config = json.load(f)\n",
    "pipelet_config['ForwardInterestDealsPipelet']['config'] = {\n",
    "    'cluster': CLUSTER,\n",
    "    'token': TOKEN,\n",
    "    'models_project_id': PROJECT_ID,\n",
    "    'forward_interest_workflow_id': forward_interest_workflow_id,\n",
    "    'forward_interest_threshold': 0.90,\n",
    "    'deal_type_workflow_id': deal_type_workflow_id,\n",
    "    'deal_type_threshold': 0.75\n",
    "}\n",
    "with open('./pipelet_config.json', 'wb') as f:\n",
    "    json.dump(pipelet_config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload pipelet to Squirro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{\"squirro_asset pipelet upload --data-file %s -c %s -t %s ./forward_interest_deals_pipelet.py forward_interest_deals\" % ('./pipelet_config.json', CLUSTER, TOKEN)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The next step is to load data in our Squirro instance. We can now run a pre-made Squirro data loader script to insert our data set. The pipelet is doing quite a bit and running locally, so be patient :) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{\"./load.sh %s %s %s\" % (CLUSTER, TOKEN, PROJECT_ID)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the dashboard\n",
    "\n",
    "Now that all the data is in and tagged, we can make our dashboard. To make it, go to your dashboard, follow the video below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=\"1025\" height=\"768\" controls>\n",
    "  <source src=\"./recommendations_dashboard.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset\n",
    "\n",
    "WARNING: This deletes the project!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_project(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
